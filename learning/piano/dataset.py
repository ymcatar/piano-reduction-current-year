'''
Handles the caching of note features generated by the Reducer.

The cache must be cleared manually when the algorithms themselves are changed.
'''

import hashlib
import h5py
import json
import logging
import numpy as np
import os
import os.path
from .score import ScoreObject


CACHE_DIR = 'sample/cache'

def hash_file(path):
    hasher = hashlib.sha256()
    with open(path, 'rb') as f:
        for block in iter(lambda: f.read(65536), b''):
            hasher.update(block)
    return hasher.hexdigest()


def load_pair(in_path, out_path, reducer, reducer_args, use_cache=False):
    loaded_from_cache = False
    cache_attrs = {
        'input_sha256': hash_file(in_path),
        'output_sha256': hash_file(out_path),
        'reducer_args': json.dumps(reducer_args, sort_keys=True),
        }
    cache_path = (
        CACHE_DIR + '/' + os.path.basename(in_path).rsplit('.', 1)[0] + '.hdf5')

    if use_cache:
        try:
            with h5py.File(cache_path, 'r') as f:
                if all(f.attrs[k] == v for k, v in cache_attrs.items()):
                    logging.info('Using cache for {}'.format(
                        os.path.basename(in_path)))
                    # Use cache
                    X = np.array(f['X'])
                    y = np.array(f['y'])

                    loaded_from_cache = True
        except OSError:
            pass

    if not loaded_from_cache:
        logging.info('Loading {}'.format( os.path.basename(in_path)))
        sample_in = ScoreObject.from_file(in_path)
        sample_out = ScoreObject.from_file(out_path)

        X = reducer.create_markings_on(sample_in)
        y = reducer.create_alignment_markings_on(sample_in, sample_out)
        y = y[:, np.newaxis]

    if use_cache and not loaded_from_cache:
        if not os.path.exists(CACHE_DIR):
            os.mkdir(CACHE_DIR)
        with h5py.File(cache_path, 'w') as f:
            f.attrs.update(cache_attrs)

            f['X'] = X
            f['y'] = y

    return X, y


def load_pairs(in_paths, out_paths, reducer, reducer_args, use_cache=False):
    Xs, ys = [], []
    for in_path, out_path in zip(in_paths, out_paths):
        X, y = load_pair(in_path, out_path, reducer, reducer_args,
                         use_cache=use_cache)
        Xs.append(X)
        ys.append(y)

    return np.vstack(Xs), np.vstack(ys)
